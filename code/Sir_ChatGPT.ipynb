{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-OA77kPcYkdu"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sir_ChatGPT\n",
        "\n",
        "Development of a Simple Informational Retrieval System obtaining guidance with ChatGPT. Tested on CISI collection with BM25 algorithm.\n",
        "\n",
        "\n",
        "Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "\n",
        "[Repositório no github](https://github.com/marcusborela/Sir-ChatGPT)"
      ],
      "metadata": {
        "id": "CcN_5-RDWeqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab latest github version](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcusborela/Sir-ChatGPT/blob/main/code/Sir_ChatGPT.ipynb) [Open In Colab latest github version]"
      ],
      "metadata": {
        "id": "ti1aFWTVgejM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VQxzYKGgMqce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 1: Coleta de dados da CISI Collection"
      ],
      "metadata": {
        "id": "2L6Y2H8MH14s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elaboração de Rotinas utilitárias"
      ],
      "metadata": {
        "id": "2HsZlZ7YlPi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mostra_dict(dicionario: dict):\n",
        "    \"\"\"\n",
        "    Imprime informações sobre o dicionário recebido como parâmetro.\n",
        "\n",
        "    Argumentos:\n",
        "    - dicionario: um dicionário a ser impresso\n",
        "\n",
        "    Retorna:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # obtém a primeira e última chave do dicionário\n",
        "    primeiro_elemento = list(dicionario.keys())[0]\n",
        "    ultimo_elemento = list(dicionario.keys())[-1]\n",
        "\n",
        "    # imprime o tamanho do dicionário e as informações sobre seus limites\n",
        "    print(f\"O dicionário tem tamanho: {len(dicionario)}\")\n",
        "    print(f\"Seus limites:\\n {primeiro_elemento}:\\n {dicionario[primeiro_elemento]},\\n {ultimo_elemento}:\\n {dicionario[ultimo_elemento]}\")\n"
      ],
      "metadata": {
        "id": "ctvgk_oNlUPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def carregar_cisi_arquivo(nome_arquivo:str, se_debug:bool=False):\n",
        "\n",
        "  # abre o arquivo CISI.ALL em modo de leitura\n",
        "  with open(nome_arquivo, \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  # inicializa o dicionário\n",
        "  documents = {}\n",
        "\n",
        "  # inicializa as variáveis de controle\n",
        "  doc_id = None\n",
        "  field = None\n",
        "  text = \"\"\n",
        "\n",
        "  # percorre as linhas do arquivo\n",
        "  for line in lines:\n",
        "    # se a linha começa com \".I\", então é um novo documento\n",
        "    if line.startswith((\".I\", \".T\", \".A\", \".W\", \".X\", \".B\")):\n",
        "      # faça algo se a linha começar com um desses valores\n",
        "        if doc_id is not None and field != \"id\":\n",
        "            documents[doc_id][field] = text.strip()\n",
        "            if se_debug:\n",
        "              print(f\"Atribuido a documents[{doc_id}][{field}] = {text.strip()}\")\n",
        "            text = \"\"\n",
        "    # se a linha começa com \".I\", então é um novo documento\n",
        "    if line.startswith(\".I\"):\n",
        "        # extrai o ID do documento da linha\n",
        "        doc_id = int(line.split()[1])\n",
        "        field = \"id\"\n",
        "        documents[doc_id] = {}\n",
        "        if se_debug:\n",
        "          print(f\"novo doc_id {doc_id}\")\n",
        "    # se a linha começa com \".T\", \".A\" ou \".W\", então é um novo campo\n",
        "    elif line.startswith(\".T\"):\n",
        "        field = \"title\"\n",
        "    elif line.startswith(\".A\"):\n",
        "        field = \"author\"\n",
        "    elif line.startswith(\".X\"):\n",
        "        field = \"reference\"\n",
        "    elif line.startswith(\".B\"):\n",
        "        field = \"bibliograph\"\n",
        "    elif line.startswith(\".W\"):\n",
        "        field = \"text\"\n",
        "    # caso contrário, é um texto que faz parte do campo atual\n",
        "    else:\n",
        "        text += line\n",
        "    if se_debug:\n",
        "      print(f'doc_id {doc_id} field {field}: {line}')\n",
        "      if doc_id == 4: break \n",
        "\n",
        "  # adiciona o último documento ao dicionário\n",
        "  if doc_id is not None:\n",
        "      documents[doc_id][field] = text.strip()\n",
        "\n",
        "  return documents"
      ],
      "metadata": {
        "id": "piuA5RbGKstq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baixa da CISI Collection"
      ],
      "metadata": {
        "id": "sZ3pW9-8L6ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# import io\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "6NSNoe3EI-gL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a URL da coleção CISI\n",
        "url = \"http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz\"\n",
        "\n",
        "# Define o caminho onde o arquivo será salvo\n",
        "file_path = \"cisi.tar\"\n",
        "\n",
        "# Faz o download do arquivo\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "# Extrai os arquivos da coleção CISI\n",
        "with tarfile.open(file_path, \"r\") as tar:\n",
        "    tar.extractall()\n"
      ],
      "metadata": {
        "id": "-QFPkX52Jzts"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('cisi.tar')"
      ],
      "metadata": {
        "id": "5wYycqvbMTGH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotina para carregar arquivos da CISI Collection\n",
        "\n",
        "Os arquivos com consultas e documentos têm um formato padrão:\n",
        ".I <id>\n",
        ".tag\n",
        "valor tag\n",
        "\n",
        "E as tags podem ser:\n",
        "\n",
        "    .T = \"title\"\n",
        "    .A = \"author\"\n",
        "    .X = \"reference\"\n",
        "    .B = \"bibliograph\"\n",
        "    .W = \"text\""
      ],
      "metadata": {
        "id": "2UwCT9VIN2XA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga do documento - CISI.ALL"
      ],
      "metadata": {
        "id": "hQAxF00EXVJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentos = carregar_cisi_arquivo('CISI.ALL')"
      ],
      "metadata": {
        "id": "EgnfWs83SD8D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_dict(documentos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOsLbLd8XM-w",
        "outputId": "5958f3c4-0d48-4bf0-9416-e0fe0a755ffd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dicionário tem tamanho: 1460\n",
            "Seus limites:\n",
            " 1:\n",
            " {'title': '18 Editions of the Dewey Decimal Classifications', 'author': 'Comaromi, J.P.', 'text': \"The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\", 'reference': '1\\t5\\t1\\n92\\t1\\t1\\n262\\t1\\t1\\n556\\t1\\t1\\n1004\\t1\\t1\\n1024\\t1\\t1\\n1024\\t1\\t1'},\n",
            " 1460:\n",
            " {'title': 'Modern Integral Information Systems for Chemistry and Chemical Technology', 'author': 'Chernyi, A.I.', 'text': \"At the present time, about 15% of all the world publications of \\nscientific and technical literature relate to chemistry and chemical\\ntechnology.  Each year throughout the world more than 250,000\\ndocuments are published:  journal papers, specifications for authors'\\ncertificates and patents, scientific and technical reports, monographs,\\netc., and in the last twenty years the number of such documents has\\nincreased by an average of 9% a year.  In these scientific documents\\ninformation on 100-150 thousand new chemical compounds is published.\", 'reference': '347\\t1\\t1460\\n452\\t1\\t1460\\n1095\\t1\\t1460\\n1136\\t1\\t1460\\n1223\\t1\\t1460\\n1261\\t1\\t1460\\n1285\\t1\\t1460\\n1460\\t6\\t1460\\n1460\\t6\\t1460'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga do documento com consultas - CISI.QRY"
      ],
      "metadata": {
        "id": "Ka-w4MufXeZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consultas = carregar_cisi_arquivo('CISI.QRY')"
      ],
      "metadata": {
        "id": "8sw1_cNLePHk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_dict(consultas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEWBFttvj1bF",
        "outputId": "f874c8c4-6d3a-422a-da37-6fe5eb675a32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dicionário tem tamanho: 112\n",
            "Seus limites:\n",
            " 1:\n",
            " {'text': 'What problems and concerns are there in making up descriptive titles?\\nWhat difficulties are involved in automatically retrieving articles from\\napproximate titles?\\nWhat is the usual relevance of the content of articles to their titles?'},\n",
            " 112:\n",
            " {'title': 'A Fast Procedure for the Calculation of Similarity Coefficients in\\nin Automatic Classification', 'author': 'Willett, P.', 'text': 'A fast algorithm is described for comparing the lists of terms representing\\ndocuments in automatic classification experiments.  The speed of the procedure\\narises from the fact that all of the non-zero-valued coefficicents for a given\\ndocument are identified together, using an inverted file to the terms in the\\ndocument collection.  The complexity and running time of the algorithm are\\ncompared with previously described procedures.', 'bibliograph': '(Information Processing & Management, Vol. 17, No. 2, 1981, pp. 53-60)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga do documento com dados de relevância - CISI.REL"
      ],
      "metadata": {
        "id": "gFNnxXRGXlpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# inicializa o dicionário de relevância por consulta\n",
        "relevancia_consulta = {}\n",
        "\n",
        "# abre o arquivo CISI.REL em modo de leitura\n",
        "with open('CISI.REL') as f:\n",
        "    # percorre as linhas do arquivo\n",
        "    for line in f.readlines():\n",
        "        # extrai o ID da consulta e do documento da linha\n",
        "        qry_id = int(line.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0])\n",
        "        doc_id = int(line.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])\n",
        "        \n",
        "        # adiciona o ID do documento na lista de relevância da consulta\n",
        "        if qry_id in relevancia_consulta:\n",
        "            relevancia_consulta[qry_id].append(doc_id)\n",
        "        else:\n",
        "            relevancia_consulta[qry_id] = []\n",
        "            relevancia_consulta[qry_id].append(doc_id)\n",
        "# Fonte de apoio: https://www.kaggle.com/code/razamh/some-changes-in-cisi-eda"
      ],
      "metadata": {
        "id": "MdN4v1nzg6AR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostra_dict(relevancia_consulta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZMSV96MeO5R",
        "outputId": "d17e8058-d884-4740-b912-6b6652ab547e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dicionário tem tamanho: 76\n",
            "Seus limites:\n",
            " 1:\n",
            " [28, 35, 38, 42, 43, 52, 65, 76, 86, 150, 189, 192, 193, 195, 215, 269, 291, 320, 429, 465, 466, 482, 483, 510, 524, 541, 576, 582, 589, 603, 650, 680, 711, 722, 726, 783, 813, 820, 868, 869, 894, 1162, 1164, 1195, 1196, 1281],\n",
            " 111:\n",
            " [328, 422, 448, 485, 503, 509]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HUtvq4hfLEVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 2: Pré-processamento dos textos de documentos e consultas"
      ],
      "metadata": {
        "id": "e007dYSoJ-zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nltk"
      ],
      "metadata": {
        "id": "gu1iJ0WVWU3z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer, PorterStemmer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "#stemmer = SnowballStemmer('english')\n"
      ],
      "metadata": {
        "id": "KLONEn8nlxPF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLgzi6qlt7UZ",
        "outputId": "16a5cfbf-b734-4e90-c630-34eed5353cc6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "SoFU0laIrmuY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desenvolvimento do código"
      ],
      "metadata": {
        "id": "bZDdSQCjLH7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessa_texto(texto,\n",
        "                      to_lower=True, \n",
        "                      remove_pontuacao=True,\n",
        "                      remove_stopwords=True,\n",
        "                      aplica_stemming=True,\n",
        "                      aplica_lematizacao=True):\n",
        "    \"\"\"\n",
        "    Função que realiza o pré-processamento de um texto.\n",
        "    \n",
        "    Parâmetros:\n",
        "    texto (str): Texto a ser pré-processado\n",
        "    to_lower (bool): Flag que indica se deve transformar o texto para lower case. Default: True\n",
        "    remove_pontuacao (bool): Flag que indica se deve remover a pontuação do texto. Default: True\n",
        "    remove_stopwords (bool): Flag que indica se deve remover as stop words do texto. Default: True\n",
        "    aplica_stemming (bool): Flag que indica se deve aplicar stemming no texto. Default: True\n",
        "    aplica_lematizacao (bool): Flag que indica se deve aplicar lematização no texto. Default: True\n",
        "    \n",
        "    Retorna:\n",
        "    str: Texto pré-processado\n",
        "    \"\"\"\n",
        "    # Transforma o texto em lower case\n",
        "    if to_lower:\n",
        "        texto = texto.lower()\n",
        "\n",
        "    # Substitute line breaks for space\n",
        "    texto = re.sub(r'\\n', ' ', texto)\n",
        "\n",
        "    # Remove pontuação\n",
        "    if remove_pontuacao:\n",
        "        texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "\n",
        "    palavras = texto.split()\n",
        "\n",
        "    # Remove stop words\n",
        "    if remove_stopwords:\n",
        "        palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stop_words]\n",
        "        palavras = palavras_sem_stopwords\n",
        "\n",
        "    # Aplica stemming\n",
        "    if aplica_stemming:\n",
        "        palavras_stemizadas = [stemmer.stem(palavra) for palavra in palavras]\n",
        "        palavras = palavras_stemizadas\n",
        "\n",
        "    # Aplica lematização\n",
        "    if aplica_lematizacao:\n",
        "        palavras_lematizadas = [lemmatizer.lemmatize(palavra) for palavra in palavras]\n",
        "        palavras = palavras_lematizadas\n",
        "\n",
        "    return ' '.join(palavras)\n"
      ],
      "metadata": {
        "id": "06S5t8XQpCoT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessa_texto(\"This is an example of text.\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V2HwAWsksS1W",
        "outputId": "ba50c3a2-a726-4f7d-9a2a-5c0698855d92"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'exampl text'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessa_texto_em_dict(parm_dict, \n",
        "                      to_lower=True, \n",
        "                      remove_pontuacao=True,\n",
        "                      remove_stopwords=True,\n",
        "                      aplica_stemming=True,\n",
        "                      aplica_lematizacao=True):\n",
        "  \"\"\"\n",
        "  Recebe um dicionário e retorna uma cópia do mesmo com os valores da chave \"text\" pré-processados.\n",
        "\n",
        "  Args:\n",
        "  parm_dict (dict): Dicionário com chaves de texto e valores em texto.\n",
        "  to_lower (bool): Transforma o texto em caixa baixa. Padrão é True.\n",
        "  remove_pontuacao (bool): Remove a pontuação do texto. Padrão é True.\n",
        "  remove_stopwords (bool): Remove as palavras de parada do texto. Padrão é True.\n",
        "  aplica_stemming (bool): Aplica a técnica de stemming no texto. Padrão é True.\n",
        "  aplica_lematizacao (bool): Aplica a técnica de lematização no texto. Padrão é True.\n",
        "\n",
        "  Returns:\n",
        "  dict: Novo dicionário com a nova chave 'texto_prep' e seus valores pré-processados.\n",
        "\n",
        "  new_dict = dict(parm_dict)  # cria uma cópia do dicionário\n",
        "  for elemento in new_dict:\n",
        "    for key in new_dict[elemento]:\n",
        "      if key == \"text\":\n",
        "          new_dict[elemento][\"text_prep\"] = preprocessa_texto(new_dict[elemento][\"text\"], to_lower=to_lower, \n",
        "                                                    remove_pontuacao=remove_pontuacao,\n",
        "                                                    remove_stopwords=remove_stopwords,\n",
        "                                                    aplica_stemming=aplica_stemming,\n",
        "                                                    aplica_lematizacao=aplica_lematizacao)\n",
        "  return new_dict\n",
        "  \"\"\"\n",
        "  new_dict = {}\n",
        "  for elemento in parm_dict:\n",
        "    for key in parm_dict[elemento]:\n",
        "      if key == \"text\":\n",
        "          new_dict[elemento] = preprocessa_texto(parm_dict[elemento][\"text\"], to_lower=to_lower, \n",
        "                                                    remove_pontuacao=remove_pontuacao,\n",
        "                                                    remove_stopwords=remove_stopwords,\n",
        "                                                    aplica_stemming=aplica_stemming,\n",
        "                                                    aplica_lematizacao=aplica_lematizacao)\n",
        "  return new_dict"
      ],
      "metadata": {
        "id": "lWl3v9JEyA7E"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste do código de pre-processamento"
      ],
      "metadata": {
        "id": "bPWyOfASYCZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert preprocessa_texto(\"This is a simple text.\").split() == ['simpl', 'text']\n"
      ],
      "metadata": {
        "id": "pv_l-rptsSzJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert preprocessa_texto(\"Hello! My name is John. Nice to meet you!\").split() == ['hello', 'name', 'john', 'nice', 'meet']\n",
        "assert preprocessa_texto(\"We are learning about Natural Language Processing.\").split() == ['learn', 'natur', 'languag', 'process']\n",
        "assert preprocessa_texto(\"The quick brown fox jumps over the lazy dog.\").split() == ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n",
        "assert preprocessa_texto(\"To be, or not to be: that is the question.\").split() == [\"question\"]\n",
        "assert preprocessa_texto(\"I'm a developer at OpenAI. I love working with AI and NLP technologies!\").split() == ['im', 'develop', 'openai', 'love', 'work', 'ai', 'nlp', 'technolog']\n",
        "assert preprocessa_texto(\"The cat is on the mat.\").split() == ['cat', 'mat']\n",
        "assert preprocessa_texto(\"An investment in knowledge pays the best interest.\").split() == ['invest', 'knowledg', 'pay', 'best', 'interest']\n",
        "assert preprocessa_texto(\"The quick brown fox jumps over the lazy dog.\").split() == ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n",
        "assert preprocessa_texto(\"To be, or not to be: that is the question.\").split() == [\"question\"]\n",
        "assert preprocessa_texto(\"I'm a developer at OpenAI. I love working with AI and NLP technologies!\").split() == ['im', 'develop', 'openai', 'love', 'work', 'ai', 'nlp', 'technolog']\n",
        "assert preprocessa_texto(\"The cat is on the mat.\").split() == ['cat', 'mat']\n",
        "assert preprocessa_texto(\"An investment in knowledge pays the best interest.\").split() == ['invest', 'knowledg', 'pay', 'best', 'interest']\n"
      ],
      "metadata": {
        "id": "p0_NzgMIZ9NA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert preprocessa_texto(\"Hello World!\").split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"Hello, World!!!\").split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"Hello World\", remove_pontuacao=False).split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"Hello World\", remove_stopwords=False).split() == ['hello', 'world']\n",
        "assert preprocessa_texto(\"I am running in the park\", aplica_stemming=False).split() == ['running', 'park']\n",
        "assert preprocessa_texto(\"I am running in the park\", to_lower=False, remove_stopwords=False, aplica_stemming=False, aplica_lematizacao=False).split() == ['I', 'am', 'running', 'in', 'the', 'park']\n",
        "assert preprocessa_texto(\"I am running in the park\", aplica_lematizacao=False).split() == ['run', 'park']\n",
        "assert preprocessa_texto(\"I am running in the park\", to_lower=False).split() == ['i', 'run', 'park']\n"
      ],
      "metadata": {
        "id": "Ah6ynUi0qgpR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentos[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WsE6S-GyBBf",
        "outputId": "d0bc10d3-8c60-4709-c253-30fb53c20344"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': '18 Editions of the Dewey Decimal Classifications',\n",
              " 'author': 'Comaromi, J.P.',\n",
              " 'text': \"The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\",\n",
              " 'reference': '1\\t5\\t1\\n92\\t1\\t1\\n262\\t1\\t1\\n556\\t1\\t1\\n1004\\t1\\t1\\n1024\\t1\\t1\\n1024\\t1\\t1'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento da coleção CISI"
      ],
      "metadata": {
        "id": "-OA77kPcYkdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consultas_prep = preprocessa_texto_em_dict(consultas)"
      ],
      "metadata": {
        "id": "84XwZTRoyA32"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consultas_prep[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QpCBfYFjeT5i",
        "outputId": "1fc60456-42c5-4986-ba4f-b382eb3d244f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'problem concern make descript titl difficulti involv automat retriev articl approxim titl usual relev content articl titl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(consultas_prep.items())[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXkJAX-hyA0b",
        "outputId": "e13d205e-ede6-42dd-b7b8-5e0524fdb8ae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1,\n",
              "  'problem concern make descript titl difficulti involv automat retriev articl approxim titl usual relev content articl titl'),\n",
              " (2,\n",
              "  'actual pertin data oppos refer entir articl retriev automat respons inform request'),\n",
              " (3, 'inform scienc give definit possibl'),\n",
              " (4, 'imag recognit method automat transform print text computerreadi form')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como o id do documento corresponde à posição do documento, para facilitar, considerarei uma lista de strings."
      ],
      "metadata": {
        "id": "twibD5qsnCuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentos_prep = preprocessa_texto_em_dict(documentos)"
      ],
      "metadata": {
        "id": "V54X2a7j1rLS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentos_prep = list(documentos_prep.values())"
      ],
      "metadata": {
        "id": "X0xJM9wM1vpm"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentos_prep[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "KTfuC8ABnOwu",
        "outputId": "8e4cffb1-0e40-4c85-e994-0febbfc51c7c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'present studi histori dewey decim classif first edit ddc publish 1876 eighteenth edit 1971 futur edit continu appear need spite ddc long healthi life howev full stori never told biographi dewey briefli describ system first attempt provid detail histori work spur growth librarianship countri abroad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa 3: Implementação de dois mecanismos de busca com BM25"
      ],
      "metadata": {
        "id": "H9j_p52kx6MC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desenvolvimento de um mecanismo de busca baseado em bm25 puro\n",
        "\n",
        "Conforme site de referência:\n",
        "\n",
        "PAIVA, Clovis.Elasticsearch: entenda a teoria por trás do mecanismo de busca textual.In: medium.com.2020; Disponível em: [https://medium.com/tentando-ser-um-unic%C3%B3rnio/elasticsearch-entenda-a-teoria-por-tr%C3%A1s-do-mecanismo-de-busca-textual-86d11bd4f69d](https://medium.com/tentando-ser-um-unic%C3%B3rnio/elasticsearch-entenda-a-teoria-por-tr%C3%A1s-do-mecanismo-de-busca-textual-86d11bd4f69d). Acesso em: 22 fev. 2023. \n"
      ],
      "metadata": {
        "id": "w5RQAYeVWtUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "gN78EvF8q2TI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "class BM25:\n",
        "\n",
        "    def __init__(self, documents: list, k1=1.5, b=0.75, epson=0.25):\n",
        "        \"\"\"\n",
        "        Inicializa um modelo BM25 com os parâmetros k1 e b definidos.\n",
        "\n",
        "        Args:\n",
        "            documents (dict): Dicionário contendo os documentos indexados por ID.\n",
        "            k1 (float): Parâmetro de ajuste da frequência de termos.\n",
        "            b (float): Parâmetro de ajuste do comprimento dos documentos.\n",
        "        \"\"\"\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.idf = {}\n",
        "        self.avgdl = 0\n",
        "        self.doc_len = {}\n",
        "        self.documents = documents\n",
        "        self.N = len(documents)\n",
        "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
        "\n",
        "        # Constrói a matriz TF-IDF usando a biblioteca sklearn\n",
        "        self.tf_idf_matrix = self.vectorizer.fit_transform(self.documents)\n",
        "\n",
        "        # Calcula o comprimento médio dos documentos da coleção\n",
        "        self._calc_avgdl()\n",
        "\n",
        "    def _calc_avgdl(self):\n",
        "        \"\"\"\n",
        "        Calcula o comprimento médio dos documentos da coleção.\n",
        "        \"\"\"\n",
        "        self.avgdl = self.tf_idf_matrix.sum(axis=1).mean()\n",
        "\n",
        "        \n",
        "    def _score(self, query_tf_idf, index: int):\n",
        "        \"\"\"\n",
        "        Calcula o escore BM25 para um documento específico em relação a uma consulta.\n",
        "\n",
        "        Args:\n",
        "            query_tf_idf: TF-IDF da consulta.\n",
        "            index (int): Índice do documento.\n",
        "\n",
        "        Returns:\n",
        "            float: Escore BM25 para o documento em relação à consulta.\n",
        "        \"\"\"\n",
        "        # print('query_tf_idf')\n",
        "        # print(query_tf_idf)\n",
        "        # print('self.tf_idf_matrix[index].T')\n",
        "        # print(self.tf_idf_matrix[index].T)\n",
        "\n",
        "        \n",
        "        prod_query_docto = np.dot(query_tf_idf,self.tf_idf_matrix[index].T)\n",
        "\n",
        "        # print(prod_query_docto.toarray())\n",
        "        # print(prod_query_docto.toarray().item())\n",
        "        prod_query_docto = prod_query_docto.toarray().item()\n",
        "        # print(f\"type prod_query_docto {type(prod_query_docto)}\")\n",
        "        val_bm25 = ((self.k1 + 1)*prod_query_docto)/(self.k1+prod_query_docto)\n",
        "        return val_bm25\n",
        "\n",
        "    def search(self, query, k=5):\n",
        "        \"\"\"\n",
        "        Busca os k documentos mais relevantes para a consulta query.\n",
        "\n",
        "        Parâmetros\n",
        "        ----------\n",
        "        query: str\n",
        "            Consulta a ser pesquisada.\n",
        "        k: int, opcional (default=5)\n",
        "            Número de documentos mais relevantes a serem retornados.\n",
        "\n",
        "        Retorna\n",
        "        -------\n",
        "        list\n",
        "            Lista de tuplas contendo o id do documento e a pontuação BM25.\n",
        "        \"\"\"\n",
        "\n",
        "        # Separa as palavras da consulta em uma lista de tokens\n",
        "        # print(f\"Query: {query}\")\n",
        "        # query = query.split()\n",
        "\n",
        "        # Aplica o vetorizador na consulta\n",
        "        query_tf_idf = self.vectorizer.transform([query])\n",
        "\n",
        "        # Dicionário de pontuação de cada documento para a consulta\n",
        "        scores = {ndx+1: self._score(query_tf_idf, ndx) for ndx, doc in enumerate(self.documents)}\n",
        "  \n",
        "        # print(f\"scores[:5]  {list(scores)[:5]}\")\n",
        "        # Ordena os documentos por ordem decrescente de pontuação e retorna os k mais relevantes\n",
        "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]"
      ],
      "metadata": {
        "id": "scQZVa3MhFah"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mecanismo_bm25 = BM25(documentos_prep)"
      ],
      "metadata": {
        "id": "6fsB4OJThFXA"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total doctos: {mecanismo_bm25.N}\\nTamanho médio: {mecanismo_bm25.avgdl}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFGE07rukSxu",
        "outputId": "180f974f-db8e-436a-c7da-b6e287862980"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total doctos: 1460\n",
            "Tamanho médio: 281.56420071632516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mecanismo_bm25.vectorizer.transform([consultas_prep[1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urvtiTv2nubD",
        "outputId": "a0272c99-a57b-47cd-82df-197f1de9dc8e"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 6487)\t4.548522096419013\n",
            "  (0, 6161)\t10.373633932200244\n",
            "  (0, 5255)\t2.725510083686854\n",
            "  (0, 5163)\t3.5155070902367176\n",
            "  (0, 4847)\t2.599216358362562\n",
            "  (0, 3760)\t3.2235966816754154\n",
            "  (0, 3366)\t3.9167438622353608\n",
            "  (0, 1995)\t4.730843653212968\n",
            "  (0, 1943)\t3.7218435232345457\n",
            "  (0, 1642)\t4.009525595686327\n",
            "  (0, 1567)\t3.249239112288753\n",
            "  (0, 909)\t3.7535922215491264\n",
            "  (0, 824)\t6.821988783002461\n",
            "  (0, 785)\t4.457550318213287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mecanismo_bm25.search(consultas_prep[1],k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwMOtSOKoCrm",
        "outputId": "052319b9-fcc6-4557-b2c0-1d93044301c6"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(589, 2.4927852279328304),\n",
              " (722, 2.4886306108594023),\n",
              " (429, 2.488317120985585),\n",
              " (820, 2.488261730465691),\n",
              " (65, 2.4867478536555807),\n",
              " (1090, 2.485626364202991),\n",
              " (1091, 2.48513987052277),\n",
              " (603, 2.483178290444875),\n",
              " (17, 2.482872891017683),\n",
              " (813, 2.4819771674183744)]"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desenvolvimento de um mecanismo de busca baseado em bm25 com acréscimo de penalização para o tamanho dos documentos\n",
        "\n",
        "Usando library rank-bm25.BM25Okapi\n",
        "\n",
        "Nessa library python, há um ajuste que considera o tamanho do documento, como bem explicado na referência citada no início desta seção."
      ],
      "metadata": {
        "id": "Lt2cYTJoWyAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25"
      ],
      "metadata": {
        "id": "6NRIRaKP14In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ca5bbe-1a9c-4a05-d238-3a08c662f9b1"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank-bm25) (1.21.6)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n"
      ],
      "metadata": {
        "id": "RTDwvNu6UeO8"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BM25_Penaliza_Tamanho_Docto:\n",
        "    def __init__(self, documentos):\n",
        "        \"\"\"\n",
        "        Inicializa o indexador.\n",
        "\n",
        "        Args:\n",
        "            documentos (list): Lista com as informações dos documentos pré-processados.\n",
        "        \"\"\"\n",
        "        self.documentos = documentos\n",
        "        self.index = None\n",
        "        self.bm25 = None\n",
        "        self.index = BM25Okapi(documentos)\n",
        "\n",
        "    def search(self, consulta, top_k=10):\n",
        "        \"\"\"\n",
        "        Realiza a busca BM25 para a consulta.\n",
        "\n",
        "        Args:\n",
        "            consulta (str): Consulta a ser buscada.\n",
        "            top_k (int): Número máximo de documentos a serem retornados. Padrão é 10.\n",
        "\n",
        "        Returns:\n",
        "            list: Lista com os índices dos documentos mais relevantes para a consulta, ordenados por relevância decrescente.\n",
        "        \"\"\"\n",
        "      \n",
        "        scores = self.index.get_scores(consulta)\n",
        "        # print(scores)\n",
        "        sorted_indexes = np.argsort(scores)[::-1]\n",
        "        # print(sorted_indexes)\n",
        "\n",
        "        # Get the top values and their indexes in a pair list\n",
        "        return [(i, scores[i]) for i in sorted_indexes[:top_k]]\n",
        "\n"
      ],
      "metadata": {
        "id": "HdqlNqHn7Y_T"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_bm25_tamanho_docto = BM25_Considerando_Tamanho_Docto(documentos_prep)"
      ],
      "metadata": {
        "id": "L4kQ61HlUeL8"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_bm25_tamanho_docto.search(consultas_prep[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPAgnMC--wT0",
        "outputId": "52e42675-cdef-4f9a-c41f-cfe565dfe509"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1283, -112.62650106298177),\n",
              " (1295, -117.00449081753162),\n",
              " (1099, -131.78342390793745),\n",
              " (1287, -135.45310000378092),\n",
              " (826, -145.30485984149763),\n",
              " (1085, -146.20343976246576),\n",
              " (1281, -146.46291901278508),\n",
              " (1319, -147.46108434334448),\n",
              " (1301, -148.7393105811567),\n",
              " (1311, -148.88804046312976)]"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    }
  ]
}